{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#input data 전처리\r\n",
    "from konlpy.tag import Kkma\r\n",
    "import math\r\n",
    "from operator import itemgetter\r\n",
    "import re\r\n",
    "from nltk import word_tokenize\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "** 가이드 **\r\n",
    "-input_sim\r\n",
    "0~15 : 가장 자유로움 \r\n",
    "15~30 : 자유로움\r\n",
    "30~45 : 조금씩 걸러짐\r\n",
    "45~60 : 많이 걸러짐   / 강제로 기업 설명을 인식시켜서 더 제한적인 슬로건\r\n",
    "60~ : 거의 다 걸러짐  / 슬로건 100개를 했을 경우 유사율 평균 70 이상은 거의 없음\r\n",
    "\r\n",
    "-input_text\r\n",
    "최대한 명사 위주의 설명\r\n",
    "영어를 쓸경우 뒤에 나오는 단어와 붙여쓰면 더 좋은 결과 ex) 'LED 마스크'보다는 'LED마스크' \r\n",
    "\"\"\"\r\n",
    "\r\n",
    "#입력한게 맞아?\r\n",
    "#best 사례 / 회원 데이터 차례\r\n",
    "#애드센스 3만원 / \r\n",
    "\r\n",
    "input_sim = 40  # input data 유사성 민감도 지정 / 숫자가 작을수록 관련 없는게 나올 확률이 커짐 / 최소 50이상 설정\r\n",
    "input_text = '커피전문기업'\r\n",
    "input_text_list = input_text.split(' ') # input data 띄어쓰기로 나누기\r\n",
    "eng_text = re.sub('[^a-zA-z]',' ',input_text).strip()\r\n",
    "# print(word_tokenize(input_text))\r\n",
    "# print(input_text_list)\r\n",
    "\r\n",
    "kkma = Kkma() #꼬마를 작용시 분모가 중복 되는 경우가 생김, 이를 제거해야 함\r\n",
    "copy=[]\r\n",
    "for txt in input_text_list :\r\n",
    "    txt_ = kkma.nouns(txt)\r\n",
    "    # print(txt_)\r\n",
    "\r\n",
    "    if len(txt_) > 1 : #(명사가 쪼개졌을 경우)\r\n",
    "        max_string = max(txt_, key=len) #가장 긴 값을 제거 (중복값)\r\n",
    "        txt_.remove(max_string)    \r\n",
    "    \r\n",
    "    copy += txt_\r\n",
    "# print(copy)\r\n",
    "\r\n",
    "if len(copy) >3 : \r\n",
    "    del_list = []\r\n",
    "    for i in range(math.ceil(len(copy)-2)) : \r\n",
    "        overlap_txt = ''.join((itemgetter(i,i+2)(copy))) # abc를 kkma로 쪼갤 경우 =>  a, ab, abc, b, c => abc 제거 => ab를 제거하는 과정 \r\n",
    "        if overlap_txt in copy :\r\n",
    "            del_list.append(overlap_txt) \r\n",
    "    #print(del_list)\r\n",
    "    [i for i in del_list if not i in copy or copy.remove(i)] #차집합인데 순서가 안 바뀜 \r\n",
    "text = ' '.join(copy)\r\n",
    "\r\n",
    "if input_sim > 45 :\r\n",
    "    text += ',' #,를 넣을 경우 강제로 기업설명으로 인식시켜서 조금 더 제한적인 슬로건 등장 \r\n",
    "\r\n",
    "#영어 슬로건이 포함 된 경우 초기상태로\r\n",
    "if eng_text :\r\n",
    "    if eng_text in input_text :\r\n",
    "        text = input_text\r\n",
    "    \r\n",
    "print(text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "커피 전문 기업\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#슬로건 생성 모델 실행\r\n",
    "import requests\r\n",
    "import json\r\n",
    "\r\n",
    "\r\n",
    "r = requests.post(\r\n",
    "    'https://train-8dgtlge21881yafjrqb4-gpt2-train-teachable-ainize.endpoint.ainize.ai/predictions/gpt-2-ko-small-finetune', #슬로건 , 없는 정제된 5에포크\r\n",
    "    headers = {'Content-Type' : 'application/json'\r\n",
    "               },\r\n",
    "    data=json.dumps({\r\n",
    "  \"text\": text,\r\n",
    "  \"num_samples\": 100,\r\n",
    "  \"length\": 20\r\n",
    "    }))\r\n",
    "\r\n",
    "#슬로건 추가\r\n",
    "slogan_list = []\r\n",
    "for slogan in r.json():\r\n",
    "    # print('============================')\r\n",
    "    # print(slogan)\r\n",
    "    slogan = slogan.split('\\n')[0]\r\n",
    "    slogan = slogan.split(',')[1:]\r\n",
    "    slogan = ', '.join(slogan)\r\n",
    "    if slogan :\r\n",
    "      slogan_list.append(slogan)\r\n",
    "      print(slogan)\r\n",
    "print(len(slogan_list),'개 완료')\r\n",
    "\r\n",
    "#슬로건 데이터 200개 생성 25초"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "인생에서 가장 맛있는 것을 맛보면\n",
      "이것이 바로 치킨전문 기업\n",
      "당신의 시간을 더 특별하게\n",
      "Don't never good\n",
      "우리는 이\n",
      "한번도 경험해보지 못한 새로운 인생\n",
      "마음을 담았습니다\n",
      "맛있는 식사하세요\n",
      "어쩌지?\n",
      "오늘의 커피\n",
      "맛있는 한끼\n",
      "나는 매일매일 새로운 라이프\n",
      "오늘도 맛있는 요리,  내일은 나뿐입니다\n",
      "맛있다면 언제든 즐겨요\n",
      "새로운 도전은 계속됩니다\n",
      "소중한 당신이 당신을 지켜주고 있습니다\n",
      "나만의 공간에 예술을 더하다\n",
      "My Face Like Your Skin\n",
      "모두의 즐거움을 위해\n",
      "THE MASTER ME,  Live Check\n",
      "당신의 모든 순간을 위해\n",
      "세상의 모든 것\n",
      "더욱 건강하게\n",
      "이제 우리집도 행복해지는 시대\n",
      "요리의 기준을 세우다\n",
      "내 몸에 더 맞는 커피\n",
      "당신의 오감만족\n",
      "Daily Morning\n",
      "진짜 제대로 된 요리가 만나다\n",
      "어디서나 쉽고 편하게\n",
      "당신에게\n",
      "맛있게 오래가고 싶습니다\n",
      "세상의 모든 카페가 당신 곁을 지켜주겠습니다\n",
      "한 번 더 도전하는 내일을\n",
      "진짜 요리사는 요리사가 아니다,  진정한 요리사\n",
      "내 삶을 바꾸는 맛있는 시간\n",
      "나의 여행은 지금부터\n",
      "나만의 시간을 갖다\n",
      "BE HAVE FULL NEW\n",
      "이제는,  진짜 피자만 골라야 할 때\n",
      "아이를 키우는 일은 혼자만의 시간이 아니다\n",
      "맛도 칼칼하고 맛도 역시 맛집도 음식도 맛있다\n",
      "당신의 라이프 스타일을 완성하다\n",
      "당신의 마음을 담았다\n",
      "당신은 지금 무엇을 하든 지금 행복해요\n",
      "내 손에서 멈출 수 없는 즐거운 변화\n",
      "We are the Moment\n",
      "세상은 지금 달라집니다\n",
      "우리 가족 행복이 행복한 한 해가 되었으면 하는 바람입니다\n",
      "맛있는 요리를 만드는 사람들의 지혜\n",
      "맛있는 한끼\n",
      "오늘의 나,  오늘의 내가 되는 시간\n",
      "다시,  나를 위한 좋은 습관,  내가 좋아하는 시간\n",
      "JUST PORTTHERE STYLE\n",
      "당신은 당신 안에 있습니다\n",
      "대한민국 NO.1,  매일매일\n",
      "오늘은 넥스트라이프에요\n",
      "우리의 인생도 함께\n",
      "오늘은 매일 커피하세요\n",
      "오늘의 시작은 바로\n",
      "우리가 원하는 커피로 다시 태어나다\n",
      "세상은 매일 바뀌니까\n",
      "Design your Life\n",
      "Yes,  Make I'm on\n",
      "다 같은 직수.써봐\n",
      "이제 한섬이 더 강해지다\n",
      "내일의 행복\n",
      "오!\n",
      "다시,  나만의 방식으로 나를 변화시킬 수 있도록\n",
      "소형가전 땐,  그 이상\n",
      "모두가 편안한 휴식시간을 만듭니다\n",
      "우리가 선택한 그 이상의 커피\n",
      "세상을 이롭게\n",
      "다르게 만드는 행복\n",
      "세상에 없던 No.1 커피전문점\n",
      "다시,  더 맛있다\n",
      "모두 나를 아는 착한 가게\n",
      "Shoot Your Life\n",
      "당신의 첫 번째 인생에 도움을 줍니다\n",
      "맛있는 한끼의 끝\n",
      "이것만 하면 된다\n",
      "이 순간에도\n",
      "YES OF MEET NOW?\n",
      "I have the chocolate\n",
      "마음의 여유를 선물하세요\n",
      "진짜 요리다\n",
      "세상의 모든 순간을 함께\n",
      "대한민국 행복의 시작\n",
      "아직도 내가 원하는 스타일\n",
      "아이를 키우는 아빠의 마음 편히\n",
      "이제 더 강해지는 맛\n",
      "내 삶을 책임질 모든 솔루션\n",
      "이 세상에,  그 누구도 생각지 못한 새로운 세상을 만듭니다\n",
      "93 개 완료\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#차집합 함수\r\n",
    "def differ_sets(a,b) : \r\n",
    "    lst = list(set(a)-set(b))\r\n",
    "    return lst\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#영어 슬로건 따로 추출\r\n",
    "import re\r\n",
    "\r\n",
    "eng_list = []\r\n",
    "for slogan in slogan_list :\r\n",
    "    slogan_ = re.sub('[^A-Za-z가-힣]', '',slogan) #영어 한글만 남기기\r\n",
    "    slogan_ = re.sub('[^가-힣]',' ', slogan_) #한글이 있으면 공백 채우기\r\n",
    "    if slogan_.isspace():    #isalpha()는 영어 또는 한글 유무를 찾아서 안 됨\r\n",
    "        eng_list.append(slogan)\r\n",
    "        \r\n",
    "print(eng_list)\r\n",
    "\r\n",
    "#차집합 \r\n",
    "kor_list = differ_sets(slogan_list, eng_list) #한국 슬로건만 있는 리스트"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\"Don't never good\", 'My Face Like Your Skin', 'THE MASTER ME,  Live Check', 'Daily Morning', 'BE HAVE FULL NEW', 'We are the Moment', 'JUST PORTTHERE STYLE', 'Design your Life', \"Yes,  Make I'm on\", 'Shoot Your Life', 'YES OF MEET NOW?', 'I have the chocolate']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\r\n",
    "from sentence_transformers import SentenceTransformer, util\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "\r\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\r\n",
    "\r\n",
    "corpus = slogan_list\r\n",
    "\r\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\r\n",
    "\r\n",
    "# Query sentences:\r\n",
    "queries = random.sample(kor_list, 3)\r\n",
    "\r\n",
    "\r\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\r\n",
    "top_k = 6\r\n",
    "for query in queries:\r\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\r\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\r\n",
    "    cos_scores = cos_scores.cpu()\r\n",
    "\r\n",
    "    #We use np.argpartition, to only partially sort the top_k results\r\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[1:top_k]\r\n",
    "\r\n",
    "    print(\"\\n======================\\n\")\r\n",
    "    print(\"Query:\", query)\r\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\r\n",
    "\r\n",
    "    for idx in top_results[0:top_k]:\r\n",
    "        print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "======================\n",
      "\n",
      "Query: 오늘도 맛있는 요리,  내일은 나뿐입니다\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "오늘의 나,  오늘의 내가 되는 시간 (Score: 0.6128)\n",
      "진짜 제대로 된 요리가 만나다 (Score: 0.4975)\n",
      "오늘은 매일 커피하세요 (Score: 0.4789)\n",
      "진짜 요리다 (Score: 0.4715)\n",
      "맛있는 요리를 만드는 사람들의 지혜 (Score: 0.4600)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#영어로는 유사도 분석이 힘들다.\r\n",
    "\r\n",
    "# from sentence_transformers import SentenceTransformer, util\r\n",
    "# import numpy as np\r\n",
    "# import random\r\n",
    "\r\n",
    "# #모델 불러오기\r\n",
    "# model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\r\n",
    "\r\n",
    "# #유사도 비교할 리스트\r\n",
    "# corpus = eng_list\r\n",
    "# corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\r\n",
    "\r\n",
    "# #비교할 슬로건 선택 => 임시로 우선 정해서 정확도 확인\r\n",
    "# queries = random.sample(eng_list, 3)\r\n",
    "\r\n",
    "# top_k = 4\r\n",
    "# for query in queries:\r\n",
    "#     query_embedding = model.encode(query, convert_to_tensor=True)\r\n",
    "#     cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\r\n",
    "#     cos_scores = cos_scores.cpu()\r\n",
    "\r\n",
    "#     #We use np.argpartition, to only partially sort the top_k results\r\n",
    "#     top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k] \r\n",
    "\r\n",
    "#     print(\"\\n======================\\n\")\r\n",
    "#     print(\"Query:\", query)\r\n",
    "#     print(\"\\nTop 5 most similar sentences in corpus:\")\r\n",
    "\r\n",
    "#     for idx in top_results[1:top_k]:\r\n",
    "#         print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#문장 유사도\r\n",
    "#개별 추출\r\n",
    "from sentence_transformers import SentenceTransformer, util\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "#모델 불러오기\r\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\r\n",
    "\r\n",
    "#회사 리스트\r\n",
    "company = pd.read_csv('datasets\\company_list.csv')\r\n",
    "company_list = company.company.values.tolist() #회사명을 리스트로\r\n",
    "\r\n",
    "#비교할 슬로건 선택 \r\n",
    "no_sim_list = [] #관련 없는 슬로건 추출\r\n",
    "total_slogan = [] #슬로건 전체를 담는 리스트 / 중첩리스트용\r\n",
    "n = 0\r\n",
    "try : #n이 증가하지 않을 경우 무한루프? \r\n",
    "    while n < 5 :\r\n",
    "        #유사도 비교할 리스트\r\n",
    "        corpus = kor_list\r\n",
    "        corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\r\n",
    "        \r\n",
    "        #유사도 비교할 문장\r\n",
    "        query = random.sample(kor_list, 1)\r\n",
    "        print(\"Query : \", query)\r\n",
    "        \r\n",
    "        #코사인 유사도 사용하여 5개 유사한 슬로건 찾기\r\n",
    "        top_k = 6 #query 포함 top 5개\r\n",
    "        query_embedding = model.encode(query, convert_to_tensor=True)\r\n",
    "        cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\r\n",
    "        cos_scores = cos_scores.cpu()\r\n",
    "        top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k] # np 사용 이유 : 순위를 순서대로 맞추기 위함\r\n",
    "        \r\n",
    "        #민감도 비교하기 위한 유사도 더하기      \r\n",
    "        sum = 0\r\n",
    "        for idx in top_results[1:top_k]:\r\n",
    "            sum += cos_scores[idx]\r\n",
    "        f_sum = float(sum)/5 #tensor to float\r\n",
    "        print(f_sum)\r\n",
    "        \r\n",
    "        #사용자 인풋 민감도 비교    \r\n",
    "        sim_list = [] #유사 슬로건 담을 리스트\r\n",
    "        sim_list2 = [] #수정된 슬로건 담을 리스트\r\n",
    "        if f_sum >= input_sim / 100 :\r\n",
    "            for idx in top_results[0:top_k-1]:\r\n",
    "                copy_ = corpus[idx].strip()\r\n",
    "                sim_list.append(copy_)\r\n",
    "            \r\n",
    "            print(sim_list)\r\n",
    "            sim_list2 = sim_list    \r\n",
    "            for i in range(len(sim_list2)) :\r\n",
    "                for c in company_list :\r\n",
    "                    if c in sim_list2[i] :\r\n",
    "                        sim_list2[i] = sim_list2[i].replace(c,'*'*len(c))\r\n",
    "       \r\n",
    "            total_slogan.append(sim_list2)\r\n",
    "            kor_list = differ_sets(kor_list, sim_list)\r\n",
    "            n += 1\r\n",
    "            #print(len(kor_list))\r\n",
    "            \r\n",
    "        else : \r\n",
    "            no_sim_list.append(query)\r\n",
    "            kor_list = differ_sets(kor_list, query)  #kor_list에서 query를 제거 \r\n",
    "            print('관련이 없는 슬로건 데이터 추가') \r\n",
    "  \r\n",
    "                \r\n",
    "                \r\n",
    "except :\r\n",
    "    print('데이터가 부족합니다.')\r\n",
    "    \r\n",
    "print('완료')\r\n",
    "#print(no_sim_list)\r\n",
    "\r\n",
    "print(total_slogan)\r\n",
    "\r\n",
    "#슬로건 25개 보여주는데 40초 / 모델 불러들어오는 시간 포함 => 다시 시작되면 2~5초"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Query :  ['휴대폰도 폰을 만듭']\n",
      "0.599919319152832\n",
      "['휴대폰도 폰을 만듭', '이것은 안드로이드 폰을 위한 폰', '당신의 폰을 살리는 기술', '가장 위대한 폰', '휴대폰으로 보는 사진이 달라졌다']\n",
      "Query :  ['모든 것을 품다']\n",
      "0.4216780662536621\n",
      "['모든 것을 품다', '모든 폰엔', '세상 모든 순간이 함께', '세상에 없던 모든 폰으로', '당신의 모든 것이 당신의 스마트폰에 있습니다. 당신과 당신의 모든 앱이 당신의 일']\n",
      "Query :  ['일상에서 쌓인 피로를 풀고 나만의 새로운 나를 발견하세요']\n",
      "0.3469064235687256\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "Query :  ['누군가는,  당신의 삶이 내일의 일상이 되도록']\n",
      "0.42057075500488283\n",
      "['누군가는,  당신의 삶이 내일의 일상이 되도록', '당신의 폰,  오늘도 당신과 함께 하겠습니다', '오늘이 제일 예쁘니까', '우리의 오늘을 위한 새로운 시작', '당신의 초시대를 위한 혁신']\n",
      "Query :  ['세상을 바꾸는 스마트폰']\n",
      "0.645846176147461\n",
      "['세상을 바꾸는 스마트폰', '세상에 없던 진짜 스마트폰', '스마트폰을 새롭게 더 가까이', '첫 스마트폰의 혁신', '누구나 쓸 수 있는 스마트 폰']\n",
      "Query :  ['SUHD의 압도적 완성']\n",
      "0.2430259943008423\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "Query :  ['우리들만의 특별함']\n",
      "0.2855290412902832\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "Query :  ['당신께도']\n",
      "0.22478210926055908\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "Query :  ['요금 걱정없이 가볍게']\n",
      "0.22463245391845704\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "Query :  ['세상이 원하는 모든 SW를 만나다']\n",
      "0.3146249771118164\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "Query :  ['오늘부터 배터리가 닳기 시작합니다']\n",
      "0.32071456909179685\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "Query :  ['모두가 인정하는 프리미엄 노트북']\n",
      "0.3232949018478394\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "Query :  ['세계 최초의 폴더형 AI']\n",
      "0.34355731010437013\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "Query :  ['이제부터 갤럭시S9에서 새로운 시작을']\n",
      "0.4143369674682617\n",
      "['이제부터 갤럭시S9에서 새로운 시작을', '새로운 시작', '이번에는 갤럭시노트S6라 더 잘라', '갤럭시 시리즈를 다시 쓰겠습니다', '우리집 폰에서 갤럭시 S III의 모든 것']\n",
      "완료\n",
      "[['휴대폰도 폰을 만듭', '이것은 안드로이드 폰을 위한 폰', '당신의 폰을 살리는 기술', '가장 위대한 폰', '휴대폰으로 보는 사진이 달라졌다'], ['모든 것을 품다', '모든 폰엔', '세상 모든 순간이 함께', '세상에 없던 모든 폰으로', '당신의 모든 것이 당신의 스마트폰에 있습니다. 당신과 당신의 모든 앱이 당신의 일'], ['누군가는,  당신의 삶이 내일의 일상이 되도록', '당신의 폰,  오늘도 당신과 함께 하겠습니다', '오늘이 제일 예쁘니까', '우리의 오늘을 위한 새로운 시작', '당신의 초시대를 위한 혁신'], ['세상을 바꾸는 스마트폰', '세상에 없던 진짜 스마트폰', '스마트폰을 새롭게 더 가까이', '첫 스마트폰의 혁신', '**나 쓸 수 있는 스마트 폰'], ['이제부터 ****9에서 새로운 시작을', '새로운 시작', '이번에는 ***노트*6라 더 잘라', '*** 시리즈를 다시 쓰겠습니다', '우리집 폰에서 *** * III의 모든 것']]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "\r\n",
    "lst1 =['아이폰이 제일 좋아','아니야 삼성 갤럭시가 더 좋아']\r\n",
    "company_list = company.company.values.tolist()\r\n",
    "len(company_list)\r\n",
    "\r\n",
    "for c in company_list :\r\n",
    "    if c in lst1[1] :\r\n",
    "        print(c)\r\n",
    "        slogan_edit = lst1[1].replace(c,'*'*len(c))\r\n",
    "        print('수정')\r\n",
    "\r\n",
    "slogan_edit"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "갤럭시\n",
      "수정\n",
      "삼성\n",
      "수정\n",
      "삼성 갤럭시\n",
      "수정\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'아니야 ******가 더 좋아'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "#문장 유사도\r\n",
    "#개별 추출\r\n",
    "from sentence_transformers import SentenceTransformer, util\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "\r\n",
    "#모델 불러오기\r\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\r\n",
    "\r\n",
    "#유사도 비교할 리스트\r\n",
    "corpus = kor_list\r\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\r\n",
    "\r\n",
    "\r\n",
    "#비교할 슬로건 선택 \r\n",
    "confirm_list = [] # 슬로건 추출\r\n",
    "n = 0\r\n",
    "try : #n이 증가하지 않을 경우 무한루프? \r\n",
    "    while n < 10 :\r\n",
    "        query = random.sample(kor_list, 1)\r\n",
    "        # print('='*40)\r\n",
    "        # print(\"Query : \", query)\r\n",
    "        kor_list = differ_sets(kor_list, query)  #kor_list에서 query를 제거 \r\n",
    "        \r\n",
    "        #코사인 유사도 사용하여 5개 유사한 슬로건 찾기\r\n",
    "        top_k = 6 #query 포함 top 5개\r\n",
    "        query_embedding = model.encode(query, convert_to_tensor=True)\r\n",
    "        cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\r\n",
    "        cos_scores = cos_scores.cpu()\r\n",
    "        top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k] # np 사용 이유 : 순위를 순서대로 맞추기 위함\r\n",
    "        \r\n",
    "        #민감도 비교하기 위한 유사도 더하기      \r\n",
    "        sum = 0\r\n",
    "        for idx in top_results[1:top_k]:\r\n",
    "            sum += cos_scores[idx]\r\n",
    "        f_sum = float(sum)/5 #tensor to float\r\n",
    "        # print(f_sum)\r\n",
    "        \r\n",
    "        #사용자 인풋 민감도 비교    \r\n",
    "        if f_sum >= input_sim / 100 :\r\n",
    "            confirm_list.append(query)\r\n",
    "            n += 1\r\n",
    "            #print(len(kor_list))\r\n",
    "            \r\n",
    "        else : \r\n",
    "            no_sim_list.append(query)\r\n",
    "            print('관련이 없는 슬로건 데이터 추가')\r\n",
    "  \r\n",
    "                \r\n",
    "                \r\n",
    "except :\r\n",
    "    print('데이터가 부족합니다.')\r\n",
    "    \r\n",
    "print('완료')\r\n",
    "print(confirm_list)\r\n",
    "\r\n",
    "#슬로건 25개 보여주는데 40초 / 모델 불러들어오는 시간 포함 => 다시 시작되면 2~5초"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "관련이 없는 슬로건 데이터 추가\n",
      "관련이 없는 슬로건 데이터 추가\n",
      "완료\n",
      "[['차원의 차이가 피부에 그대로'], ['기대 이상의 내 피부'], ['눈빛은 그대로,  빛은 그대로'], ['시크하다'], ['피부장벽 보습을 업으로 바꾸다'], ['수분으로 숨쉬는 피부 앰플, 숨쉬고 싶은 피부'], ['여전히 촉촉'], ['아름다움을 입다'], ['촉촉하게'], ['그녀들의 피부 자신감']]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('exam_cv2': conda)"
  },
  "interpreter": {
   "hash": "19a2027c367e4a8fbf50703f7b521df71edff403eb9eba2200ef5f1febf03a5b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}