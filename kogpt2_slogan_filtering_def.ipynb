{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#input data 전처리\r\n",
    "from konlpy.tag import Kkma\r\n",
    "from operator import itemgetter\r\n",
    "import re\r\n",
    "from nltk import word_tokenize\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "** 가이드 **\r\n",
    "-input_sim\r\n",
    "0~15 : 가장 자유로움 \r\n",
    "15~30 : 자유로움\r\n",
    "30~45 : 조금씩 걸러짐\r\n",
    "45~60 : 많이 걸러짐   / 강제로 기업 설명을 인식시켜서 더 제한적인 슬로건\r\n",
    "60~ : 거의 다 걸러짐  / 슬로건 100개를 했을 경우 유사율 평균 70 이상은 거의 없음\r\n",
    "\r\n",
    "-input_text\r\n",
    "최대한 명사 위주의 설명\r\n",
    "영어를 쓸경우 뒤에 나오는 단어와 붙여쓰면 더 좋은 결과 ex) 'LED 마스크'보다는 'LED마스크' \r\n",
    "\"\"\"\r\n",
    "\r\n",
    "def input_data(sim, input_text) :\r\n",
    "    input_sim = sim  # input data 유사성 민감도 지정 / 숫자가 작을수록 관련 없는게 나올 확률이 커짐 / 최소 50이상 설정\r\n",
    "    input_text = input_text\r\n",
    "    input_text_list = input_text.split(' ') # input data 띄어쓰기로 나누기\r\n",
    "    eng_text = re.sub('[^a-zA-z]',' ',input_text).strip()\r\n",
    "    # print(word_tokenize(input_text))\r\n",
    "    # print(input_text_list)\r\n",
    "\r\n",
    "    kkma = Kkma() #꼬마를 작용시 분모가 중복 되는 경우가 생김, 이를 제거해야 함\r\n",
    "    copy=[]\r\n",
    "    for txt in input_text_list :\r\n",
    "        txt_ = kkma.nouns(txt)\r\n",
    "        # print(txt_)\r\n",
    "\r\n",
    "        if len(txt_) > 1 : #(명사가 쪼개졌을 경우)\r\n",
    "            max_string = max(txt_, key=len) #가장 긴 값을 제거 (중복값)\r\n",
    "            txt_.remove(max_string)    \r\n",
    "        \r\n",
    "        copy += txt_\r\n",
    "    # print(copy)\r\n",
    "\r\n",
    "    if len(copy) >3 : \r\n",
    "        del_list = []\r\n",
    "        for i in range(len(copy)-2) : \r\n",
    "            overlap_txt = ''.join((itemgetter(i,i+2)(copy))) # abc를 kkma로 쪼갤 경우 =>  a, ab, abc, b, c => abc 제거 => ab를 제거하는 과정 \r\n",
    "            if overlap_txt in copy :\r\n",
    "                del_list.append(overlap_txt) \r\n",
    "        #print(del_list)\r\n",
    "        [i for i in del_list if not i in copy or copy.remove(i)] #차집합인데 순서가 안 바뀜 \r\n",
    "    text = ' '.join(copy)\r\n",
    "\r\n",
    "    if input_sim > 45 :\r\n",
    "        text += ',' #,를 넣을 경우 강제로 기업설명으로 인식시켜서 조금 더 제한적인 슬로건 등장 \r\n",
    "\r\n",
    "    #영어 슬로건이 포함 된 경우 초기상태로\r\n",
    "    if eng_text :\r\n",
    "        if eng_text in input_text :\r\n",
    "            text = input_text\r\n",
    "    \r\n",
    "    return text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#슬로건 생성 모델 실행\r\n",
    "import requests\r\n",
    "import json\r\n",
    "\r\n",
    "def slogan_generate(text) : \r\n",
    "  r = requests.post(\r\n",
    "      'https://train-8dgtlge21881yafjrqb4-gpt2-train-teachable-ainize.endpoint.ainize.ai/predictions/gpt-2-ko-small-finetune', #슬로건 , 없는 정제된 5에포크\r\n",
    "      headers = {'Content-Type' : 'application/json'\r\n",
    "                },\r\n",
    "      data=json.dumps({\r\n",
    "    \"text\": text,\r\n",
    "    \"num_samples\": 100,\r\n",
    "    \"length\": 20\r\n",
    "      }))\r\n",
    "\r\n",
    "  #슬로건 추가\r\n",
    "  slogan_list = []\r\n",
    "  for slogan in r.json():\r\n",
    "      slogan = slogan.split('\\n')[0]\r\n",
    "      slogan = slogan.split(',')[1:]\r\n",
    "      slogan = ', '.join(slogan)\r\n",
    "      if slogan :\r\n",
    "        slogan_list.append(slogan)\r\n",
    "        # print(slogan)\r\n",
    "  print(len(slogan_list),'개 완료')\r\n",
    "  \r\n",
    "  return slogan_list\r\n",
    "\r\n",
    "#슬로건 데이터 200개 생성 25초"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#한국 슬로건만 추출\r\n",
    "import re\r\n",
    "\r\n",
    "#차집합 함수\r\n",
    "def differ_sets(a,b) : \r\n",
    "    lst = list(set(a) - set(b))\r\n",
    "    return lst\r\n",
    "\r\n",
    "def kor_slogan(slogan_list) :\r\n",
    "    eng_list = []\r\n",
    "    for slogan in slogan_list :\r\n",
    "        slogan_ = re.sub('[^A-Za-z가-힣]', '',slogan) #영어 한글만 남기기\r\n",
    "        slogan_ = re.sub('[^가-힣]',' ', slogan_) #한글이 있으면 공백 채우기\r\n",
    "        if slogan_.isspace():    #isalpha()는 영어 또는 한글 유무를 찾아서 안 됨\r\n",
    "            eng_list.append(slogan)\r\n",
    "            \r\n",
    "    print(eng_list)\r\n",
    "\r\n",
    "    #차집합 \r\n",
    "    kor_list = differ_sets(slogan_list, eng_list) #한국 슬로건만 있는 리스트    \r\n",
    "    \r\n",
    "    return kor_list, eng_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#슬로건 결과 리스트로 반환\r\n",
    "from sentence_transformers import SentenceTransformer, util\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "\r\n",
    "def slogan_all (kor_list, input_sim) :\r\n",
    "    #모델 불러오기\r\n",
    "    model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\r\n",
    "\r\n",
    "    #유사도 비교할 리스트\r\n",
    "    corpus = kor_list\r\n",
    "    corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\r\n",
    "\r\n",
    "\r\n",
    "    #비교할 슬로건 선택 \r\n",
    "    no_sim_list = [] #관련 없는 슬로건 추출\r\n",
    "    total_slogan = [] #슬로건 전체를 담는 리스트 / 중첩리스트용\r\n",
    "    n = 0\r\n",
    "    try : #n이 증가하지 않을 경우 무한루프? \r\n",
    "        while n < 4 :\r\n",
    "            #유사도 비교할 리스트\r\n",
    "            corpus = kor_list\r\n",
    "            corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\r\n",
    "            \r\n",
    "            #유사도 비교할 문장\r\n",
    "            query = random.sample(kor_list, 1)\r\n",
    "            print('='*40)\r\n",
    "            print(\"Query : \", query)\r\n",
    "            kor_list = differ_sets(kor_list, query)  #kor_list에서 query를 제거 \r\n",
    "            \r\n",
    "            #코사인 유사도 사용하여 5개 유사한 슬로건 찾기\r\n",
    "            top_k = 6 #query 포함 top 5개\r\n",
    "            query_embedding = model.encode(query, convert_to_tensor=True)\r\n",
    "            cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\r\n",
    "            cos_scores = cos_scores.cpu()\r\n",
    "            top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k] # np 사용 이유 : 순위를 순서대로 맞추기 위함\r\n",
    "            \r\n",
    "            #민감도 비교하기 위한 유사도 더하기      \r\n",
    "            sum = 0\r\n",
    "            for idx in top_results[1:top_k]:\r\n",
    "                sum += cos_scores[idx]\r\n",
    "            f_sum = float(sum)/5 #tensor to float\r\n",
    "            print(f_sum)\r\n",
    "            \r\n",
    "            #사용자 인풋 민감도 비교    \r\n",
    "            sim_list = [] #유사 슬로건 담을 리스트\r\n",
    "            if f_sum >= input_sim / 100 :\r\n",
    "                for idx in top_results[0:top_k-2]:\r\n",
    "                    sim_list.append(corpus[idx].strip())\r\n",
    "                print(sim_list)\r\n",
    "                total_slogan.append(sim_list)\r\n",
    "                kor_list = differ_sets(kor_list, sim_list)\r\n",
    "                n += 1\r\n",
    "                #print(len(kor_list))\r\n",
    "                \r\n",
    "            else : \r\n",
    "                no_sim_list.append(query)\r\n",
    "                print('관련이 없는 슬로건 데이터 추가')\r\n",
    "    \r\n",
    "                    \r\n",
    "                    \r\n",
    "    except :\r\n",
    "        print('데이터가 부족합니다.')\r\n",
    "        \r\n",
    "    print('완료')\r\n",
    "    #print(no_sim_list)\r\n",
    "\r\n",
    "    print(total_slogan)\r\n",
    "\r\n",
    "    return total_slogan\r\n",
    "#슬로건 25개 보여주는데 40초 / 모델 불러들어오는 시간 포함 => 다시 시작되면 2~5초"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}